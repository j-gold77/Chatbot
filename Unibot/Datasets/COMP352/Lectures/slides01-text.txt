Analysis of AlgorithmsAnalysis of Algorithms1Analysis of AlgorithmsDr. Aiman HannaDepartment of Computer Science & Software Engineering Concordia University, Montreal, CanadaThese slides have been extracted, modified and updated from original slides of :Data Structures and Algorithms in Java, 5th edition. John Wiley& Sons, 2010. ISBN 978-0-470-38326-1.Data Structures and the Java Collections Framework by William J. Collins, 3rdedition, ISBN 978-0-470-48267-4. Both books are published by Wiley.Copyright © 2010-2011 WileyCopyright © 2010 Michael  T. Goodrich, Roberto TamassiaCopyright © 2011 William J. CollinsCopyright © 2011-2021 Aiman Hanna All rights reserved Analysis of Algorithms 2How to Estimate Efficiency?  Correctness of a method depends merely on whether the algorithm performs what it is supposed to do. Clearly, efficiency is hence different than correctness. Efficiency can be measured in many ways; i.e: Less memory utilization Faster execution time Quicker release of allocated recourses etc. How efficiency can then be measured? Measurement should be independent of used software (i.e. compiler, language, etc.) and hardware (CPU speed, memory size, etc.) Particularly, run-time analysis can have serious weaknessesAnalysis of Algorithms 3Experimental Studies Write a program implementing the algorithm. Run the program with inputs of varying size and composition. Use a method like System.currentTimeMillis() to get an accurate measure of the actual running time. Plot the results.01000200030004000500060007000800090000 50 100Input SizeTime (ms)Analysis of Algorithms 4Limitations of Experiments It is necessary to implement the algorithm, which may be difficult/costly. Results may not be indicative of the running time on other inputs not included in the experiment.  In order to compare two algorithms, the same hardware and software environments must be used In some multiprogramming environments, such as Windows, it is very difficult to determine how long a single task takes (since there is so much going behind the scene). Analysis of Algorithms 5How to Estimate Efficiency?  Efficiency, to a great extent, depends on how the method is defined. An abstract analysis that can be performed by direct investigation of the method definition is hence preferred.  Ignore various restrictions; i.e: CPU speed Memory limits; for instance allow an int variable to take any allowed integer value, and allow arrays to be arbitrarily large  etc. Since the method is now unrelated to specific computer environment, we refer to it as algorithm.Analysis of Algorithms 6Estimating Running Time How can we estimate the running/execution-time from algorithm’s definition? Consider the number of executed statements, in a trace of the algorithm, as a measurement of running- time requirement. This measurement can be represented as function of the “size” of the problem. The running time of an algorithm typically grows with the input size.Analysis of Algorithms 7Estimating Running Time We focus on the worst case of running time since this is crucial to many applications such as games, finance, robotics, etc.  Given a method of a problem of size n, find worstTime(n) , which is the maximum number of executed statements in a trace, considering all possible parameters/input values.020406080100120Running Time1000 2000 3000 4000Input Sizebest caseaverage caseworst caseAnalysis of Algorithms 8Estimating Running TimeExample: Assume an array a [0 … n –1] of int, and assume the following trace:for (int i = 0; i < n - 1; i++)if (a [i] > a [i + 1])System.out.println (i);What is worstTime(n)?Analysis of Algorithms 9Estimating Running Time That is, worstTime(n) is: 4n – 2.Statement Worst  Case Number of Executionsi = 0 1i < n – 1 ni++ n - 1a[i] > a[i+1] n - 1System.out.println() n - 1Analysis of Algorithms 10Estimating Running Time See aboveMeanCount() method What is worstTime(n)?http://www.aimanhanna.com/concordia/comp352/aboveMeanCount%20method.java.docAnalysis of Algorithms 11Estimating Running TimeworstTime(n ) of aboveMeanCount() methodStatements Worst  # of Executionsdouble[] a, double mean (assignment of 1st & 2nd arguments)1 + 1n = a.length, count = 0 1 + 1i = 0, return count 1 + 1i < n n + 1i++ na[i] > mean ncount++ n – 1= 4n + 6Analysis of Algorithms 12Pseudocode High-level description of an algorithm. More structured than English prose. Less detailed than a program. Preferred notation for describing algorithms Hides program design issues.Algorithm arrayMax(A, n)Input array A of n integersOutput maximum element of AcurrentMax ← A[0]for i ← 1 to n − 1 doif A[i] > currentMax thencurrentMax ← A[i]return currentMaxExample: find max element of an arrayAnalysis of Algorithms 13Pseudocode Details Control flow if … then … [else …] while … do … repeat … until … for … do … Indentation replaces braces  Method declarationAlgorithm method (arg [, arg…])Input …Output … Method callvar.method (arg [, arg…]) Return valuereturn expression Expressions←Assignment(like = in Java)= Equality testing(like == in Java)n2 Superscripts and other mathematical formatting allowedAnalysis of Algorithms 14Seven Important Functions Seven functions often appear in algorithm analysis: Constant ≈ 1 Logarithmic ≈ log n Linear ≈ n N-Log-N ≈ n log n Quadratic ≈ n2 Cubic ≈ n3 Exponential ≈ 2n 1E-11E+11E+31E+51E+71E+91E+111E+131E+151E+171E+191E+211E+231E+251E+271E+291E-1 1E+2 1E+5 1E+8T(n)nCubicQuadraticLinearFunctions Graphed Using “Normal” Scale15Analysis of Algorithmsg(n) = 2ng(n) = 1g(n) = lg ng(n) = n lg ng(n) = ng(n) = n2g(n) = n3Slide by Matt Stallmann included with permission.Analysis of Algorithms 16The Random Access Machine (RAM) Model A CPU. A potentially unbounded bank of memory cells, each of which can hold an arbitrary number or character.012Memory cells are numbered and accessing any cell in memory takes unit time.Analysis of Algorithms 17Primitive Operations Basic computations performed by an algorithm. Identifiable in pseudocode. Largely independent from the programming language. Exact definition not important (we will see why later). Assumed to take a constant amount of time in the RAM model. Examples: Evaluating an expression Assigning a value to a variable Indexing into an array Calling a method Returning from a methodAnalysis of Algorithms 18Counting Primitive Operations By inspecting the pseudocode, we can determine the maximum number of primitive operations executed by an algorithm, as a function of the input size.Algorithm compareValues(A, n)Input array A of n integersOutput display all elements larger than following ones# of operationsfor i ← 0 to n − 2 do n − 1if A[i] > A[i+1] then n − 1display i n − 1increment counter i n − 1Total 4n − 4Analysis of Algorithms 19Estimating Running Time Algorithm compareValues executes 4n − 4 primitive operations in the worst case.   Define:a = Time taken by the fastest primitive operationb = Time taken by the slowest primitive operation Let T(n) be the running time of compareValues.Thena (4n − 4) ≤ T(n) ≤ b(4n − 4) Hence, the running time T(n) is bounded by two linear functionsAnalysis of Algorithms 20Growth Rate of Running Time Changing the hardware/ software environment  Affects T(n) by a constant factor, but Does not alter the growth rate of T(n) The linear growth rate of the running time T(n) is an intrinsic property of algorithm compareValuesWhy Growth Rate Matters21Analysis of AlgorithmsSlide by Matt Stallmann included with permission.if runtime is... time for n + 1 time for 2 n time for 4 nc log n c log (n + 1) c (log n + 1) c(log n + 2)c n c (n + 1) 2c n 4c nc n log n~ c n log n+  c n2c n log n + 2cn4c n log n + 4cnc n2 ~ c n2 + 2c n 4c n2 16c n2c n3 ~ c n3 + 3c n2 8c n3 64c n3c 2n c 2 n+1 c 2 2n c 2 4nruntimequadrupleswhen problemsize doublesComparison of Two Algorithms22Analysis of AlgorithmsSlide by Matt Stallmann included with permission.insertion sort isn2 / 4merge sort is2 n lg nsort a million items?insertion sort takesroughly 70 hourswhilemerge sort takesroughly 40 secondsThis is a slow machine, but if100 x as fast then it’s 40 minutesversus less than 0.5 secondsAnalysis of Algorithms 23Constant Factors The growth rate is not affected by constant factors or  lower-order terms Examples 102n + 105 is a linear function 105n2 + 108n is a quadratic function1E-11E+11E+31E+51E+71E+91E+111E+131E+151E+171E+191E+211E+231E+251E-1 1E+1 1E+3 1E+5 1E+7 1E+9T(n)nQuadraticQuadraticLinearLinearAnalysis of Algorithms 24Big-O Notation We do NOT need to calculate the exact worst time since it is only an approximation of time requirements.  Instead, we can just approximate that time by means of “Big-O” notation.  That is quite satisfactory since it gives us approximation of an approximation! 1101001,00010,0001 10 100 1,000n3n2n+10nAnalysis of Algorithms 25Big-O Notation The basic idea is to determine an upper bound for the behavior of the algorithm/function.  In other words, to determine how bad the performance of the algorithm can get! If some function g(n) is an upper bound of function  f(n), then we say that f(n) is Big-O of g(n). Analysis of Algorithms 26Big-O Notation Specifically, Big-O is defined as follows: Given functions f(n) and g(n), we say that f(n) is O(g(n)) if there are positive constants c and n0 such thatf(n) ≤ cg(n)  for n ≥ n0 The idea is that if f(n) is O(g(n)) then it is bounded above (cannot get bigger than) some constant times g(n).Analysis of Algorithms 27Big-O Notation Further, by a standard abuse of notation, we often associate a function with the value is calculates.  For instance, if g(n) = n3, for n = 0, 1, 2,…., then instead of saying that f(n) is O(g(n)), we say f(n) is O(n3).Analysis of Algorithms 28Big-O Notation Example 1: What is O() if f(n) = 2n + 10? 2n ≤ 2n for n ≥ 0 10 ≤ 10n for n ≥ 1So, for any n ≥ 1 2n + 10 ≤ 12n  consider c = 12, n0 = 1  g(n) = nConsequently, the above f(n) is O(n). Analysis of Algorithms 29Big-O Notation In general, if f(n) is a polynomial function, which is of the form:aini + ai - 1ni – 1 + ai - 2ni – 2 + … + a1n + a0Then, we can directly establish that f(n) is O(ni).Proof: Choose n0 = 1, and  c = |ai| + |ai – 1| + |ai – 2| + … + |a1| + |a0|Analysis of Algorithms 30Big-O Notation Example 2: What is O() if f(n) = 3n4 + 6n3 + 10n2 + 5n + 4? 3n4 ≤ 3n4 for n ≥ 0 6n3 ≤ 6n4 for n ≥ 0 10n2 ≤ 10n4 for n ≥ 0 5n ≤ 5n4 for n ≥ 0 4 ≤ 4n4 for n ≥ 1So, for any n ≥ 1 3n4 + 6n3 + 10n2 + 5n + 4 ≤ 28n4 consider c = 28, n0 = 1  g(n) = n4Consequently, the above f(n) is O(n4). Analysis of Algorithms 31Big-O Notation When determining O(), we can (and actually do) ignore the logarithmic base. Proof: Assume that f(n) is O(loga n), for some positive constant a. Then f(n) ≤ C * loga n for some positive constant C and some n0 ≤ n By logarithmic fundamentals, loga n = loga b * logb n, for any n > 0 Let C1 = C * loga b. Then for all n ≥ n0f(n) ≤ C * loga n = C * loga b * logb n = C1 * logb n f(n) is O(logb n).Analysis of Algorithms 32Big-O Notation Example 3: What is O() if f(n) = 3 log n + 5 3 log n ≤ 3 log n for n ≥ 1 5 ≤ 5 log n for n ≥ 2So, for any n ≥ 2 3 log n + 5 ≤ 8 log n  consider c = 8, n0 = 2  g(n) = log nConsequently, the above f(n) is O(log n). Analysis of Algorithms 33Big-O Notation Nested loops are significant when estimating O(). Example 4:Consider the following loop segment, what is O()? for (int i = 0; i < n; i++ )for (int j = 0; j < n; j++ )…………… The outer loop has 1 + (n + 1) + n executions.  The inner loop has n(1 + (n + 1) + n ) executions. Total is: 2n2 + 4n + 2  O(n2). Hint: As seen in Example 2 for polynomial functionsAnalysis of Algorithms 34Big-O Notation Important Note: Big-O only gives an upper bound of the algorithm. However, if f(n) is O(n), then it is also O(n + 10), O(n3), O(n2 + 5n + 7), O(n10), etc.  We, generally, choose the smallest element from this hierarchy of orders.  For example, if f(n) = n + 5, then we choose O(n), even though f(n) is actually also O(n log n), O(n4), etc.  Similarly,  we write O(n) instead of O(2n + 8), O(n –log n), etc. Analysis of Algorithms 35Big-O Notation Elements of the Big-O hierarchy can be as:O(1) ⊂ O(log n) ⊂ O(n½) ⊂ O(n) ⊂ O(n log n) ⊂O(n2) ⊂ O(n3) ⊂ …….. ⊂ O(2n) ⊂ …….. Where the symbol “⊂”, indicates “is contained in”. Analysis of Algorithms 36Big-O Notation The following table provides some examples:Sample Functions Order of O()f(n) = 3000f(n) = (n * log2(n+1) + 2) / (n+1)f(n) = (500 log2 n) + n / 100000f(n) = (n * log10 n) + 4n + 8f(n) = n * (n + 1) / 2f(n) = 3500 n100 + 2nO(1)O(log n)O(n)O(n log n)O(n2)O(2n)Analysis of Algorithms 37Big-O Notation Warning: One danger of Big-O is that it can be misleading when the values of n are small.  For instance, consider the following two functions f(n) and g(n) for n ≥ 0f1(n) = 1000 n  f1(n) is hence O(n)f2(n) = n2 / 10  f2(n) is hence O(n2)However, and despite of the fact that f2(n) has a higher/worst order than the one of f1(n), f1(n) is actually greater than f2(n), for all values of n less than 10,000! Analysis of Algorithms 38Finding Big-O Estimates Quickly  Case 1: Number of executions is independent of n O(1) Example: // Constructor of a Car classpublic Car(int nd, double pr) {numberOfDoors = nd;price = pr;}Example: for (int j = 0; j < 10000; j++ )System.out.println(j);Analysis of Algorithms 39Finding Big-O Estimates Quickly  Case 2: The splitting rule  O(log n) Example: while(n > 1) {n = n / 2;…;}Example: See the binary search method in Recursion6.java& Recursion7.javahttp://aimanhanna.com/concordia/comp249/Recursion6.java.dochttp://aimanhanna.com/concordia/comp249/Recursion7.java.docAnalysis of Algorithms 40Finding Big-O Estimates Quickly  Case 3: Single loop, dependent on n  O(n) Example: for (int j = 0; j < n; j++ )System.out.println(j);Note: It does NOT matter how many simple statement (i.e. no inner loops) are executed in the loop. For instance, if the loop has k statements, then there is k*n executions of them, which will still lead to O(n).Analysis of Algorithms 41Finding Big-O Estimates Quickly  Case 4: Double looping dependent on n & splitting  O(n log n) Example: for (int j = 0; j < n; j++ ){m = n;while (m > 1) {m = m / 2;…;// Does not matter how many statements are here}}Analysis of Algorithms 42Finding Big-O Estimates Quickly  Case 4: Double looping dependent on n O(n2) Example: for (int i = 0; i < n; i++ )for (int j = 0; j < n; j++ ){…;// Does not matter how many statements are here}Analysis of Algorithms 43Finding Big-O Estimates Quickly  Case 4 (Continues): Double looping dependent on n O(n2) Example: for (int i = 0; i < n; i++ )for (int j = i; j < n; j++ ){…;// Does not matter how many statements are here}The number of executions of the code segment is as follows: n + (n-1) + (n-2) + … + 3 + 2 + 1Which is: n(n + 1) / 2 = ½ n2 + ½ n  O(n2)Analysis of Algorithms 44Finding Big-O Estimates Quickly  Case 5: Sequence of statements with different O( ) O(g1(n)) + O(g2(n)) + … = O(g1(n) + g2(n) + …) Example: for (int i = 0; i < n; i++ ){ ...}for (int i = 0; i < n; i++ )for (int j = i; j < n; j++ ){ ...}The first loop is O(n) and the second is O(n2). The entire segment is hence O(n) + O(n2), which is equal to O(n + n2), which is in this case O(n2 ). Analysis of Algorithms 45Asymptotic Algorithm Analysis In computer science and applied mathematics, asymptotic analysis is a way of describing limiting behaviours (may approach ever nearer but never crossing!). Asymptotic analysis of an algorithm determines the running time in big-O notation. To perform the asymptotic analysis We find the worst-case number of primitive operations executed as a function of the input size We then express this function with big-O notationAnalysis of Algorithms 46Asymptotic Algorithm Analysis Example: We determine that algorithm compareValuesexecutes at most 4n − 4 primitive operations We say that algorithm compareValues “runs in O(n) time”, or has a “complexity” of O(n)Note: Since constant factors and lower-order terms are eventually dropped anyhow, we can disregard them when counting primitive operations.Analysis of Algorithms 47Asymptotic Algorithm Analysis If two algorithms A & B exist for solving the same problem, and, for instance, A is O(n) and B is O(n2), then we say that A is asymptotically better than B(although for a small time B may have lower running time than A).   To illustrate the importance of the asymptotic point of view, let us consider three algorithms that perform the same operation, where the running time (in µs) is as follows, where n is the size of the problem: Algorithm1: 400n Algorithm2: 2n2 Algorithm3: 2nAnalysis of Algorithms 48Asymptotic Algorithm Analysis Which of the three algorithms is faster?  Notice that Algorithm1 has a very large constant factor compared to the other two algorithms! Running Time ( µs) Maximum Problem Size (n) that can be solved in:1 Second 1 Minute 1 HourAlgorithm 1400n2,500(400 * 2,500 = 1000,000)150,000 9 MillionAlgorithm 22n2707(2 * 7072 ≈ 1000,000)5,477 42,426Algorithm 32n19(only 19, since 220 would exceed 1000,000)25 31Analysis of Algorithms 49Asymptotic Algorithm Analysis Let us further illustrate asymptotic analysis with two algorithms that would compute prefix averages. Given an array X storing nnumbers, we need to construct an array A such that: A[i] is the average of X[0] +X[1] + … + X[i]) 051015202530351 2 3 4 5 6 7XA10 16 4 18 7 23 27 3910 13 10 12 11 13 15 18XAAnalysis of Algorithms 50Asymptotic Algorithm Analysis That is, the i-th prefix average of an array X is average of the first (i + 1) elements of X:A[i] = (X[0] + X[1] + … + X[i])/(i+1) Computing prefix average has applications to financial analysis; for instance the average annual return of a mutual fund for the last year, three years, ten years, etc. 051015202530351 2 3 4 5 6 7XAAnalysis of Algorithms 51Prefix Averages (Quadratic)The following algorithm computes prefix averages in quadratic time (n2) by applying the definitionAlgorithm prefixAverages1(X, n)Input array X of n integersOutput array A of prefix averages of X # of operationsA ← new array of n integers nfor i ← 0 to n − 1 do ns ← X[0] nfor j ← 1 to i do 1 + 2 + …+ (n − 1)s ← s + X[j] 1 + 2 + …+ (n − 1)A[i] ← s / (i + 1) nreturn A 1Analysis of Algorithms 52Prefix Averages (Quadratic) Hence, to calculate the sum n integers, the algorithm needs (from the segment that has the two loops) n(n + 1) / 2 operations.  In other words, prefixAverages1 isO(1 + 2 + …+ n) = O(n(n + 1) / 2)  O(n2)Analysis of Algorithms 53Prefix Averages (Linear)The following algorithm computes prefix averages in linear time (n) by keeping a running sumAlgorithm prefixAverages2(X, n)Input array X of n integersOutput array A of prefix averages of X # of operationsA ← new array of n integers ns ← 0 1for i ← 0 to n − 1 do ns ← s + X[i] nA[i] ← s / (i + 1) nreturn A 1Algorithm prefixAverages2 runs in O(n) time, which is clearly better than prefixAverages1.Analysis of Algorithms 54Big-Omega, Big-Theta &Plain English! In addition to Big-O, there are two other notations that are used for algorithm analysis: Big-Omega and Big-Theta. While Big-O provides an upper bound of a function, Big-Omega provides a lower bound.  In other words, while Big-O indicates that an algorithm behavior “cannot be any worse than”, Big-Omega indicates that it “cannot be any better than”.Analysis of Algorithms 55Big-Omega, Big-Theta &Plain English! Logically, we are often interested in worst-case estimations, however knowing the lower bound can be significant when trying to achieve an optimal solution. big-OmegaBig-Omega is defined as follows: Given functions f(n) and g(n), we say that f(n) is Ω(g(n)) if there are positive constants c and n0 such thatf(n) ≥ cg(n)  for n ≥ n0Analysis of Algorithms 56Big-Omega, Big-Theta &Plain English! Example: 3n log n + 2n  is  Ω(n log n)Proof: 3n log n + 2n ≥ 3n log n ≥ n log n for every n ≥ 1 Example: 3n log n + 2n  is  Ω(n)Proof: 3n log n + 2n ≥ 2n ≥ n for every n ≥ 1Analysis of Algorithms 57Big-Omega, Big-Theta &Plain English! Notice that: … Ω(2n) ⊂ Ω(n3) ⊂ Ω(n2) ⊂ Ω(n log n) ⊂Ω(n) ⊂ Ω(n½)  ⊂ … ⊂ Ω(log n) ⊂ … ⊂ Ω(1)Where the symbol “⊂”, indicates “is contained in”.  It should be noted that in “many” cases, a method that is O( ) is also Ω( ). Analysis of Algorithms 58Big-Ω Example 1 (Revised): What are O() and Ω() if f(n) = 2n + 10? As seen before, the method is O(n).  Now,  2n + 10 ≥ 2n ≥ n for n ≥ 0So, for any n ≥ 0 2n + 10 ≥ n  consider c = 1, n0 = 0  g(n) = n  Ω(n)Consequently, the above f(n) is O(n), and is also Ω(n) . Analysis of Algorithms 59Big-Ω Example 2 (Revised): What are O() and Ω() if f(n) = 3n4 + 6n3 + 10n2 + 5n + 4?As seen before, the method is O(n4).  Now,  3n4 + 6n3 + 10n2 + 5n + 4 ≥ 3n4 for n ≥ 0 3n4 ≥ n4 for n ≥ 0So, for any n ≥ 0 3n4 + 6n3 + 10n2 + 5n + 4 ≥ n4 consider c = 1, n0 = 0  g(n) = n4Consequently, the above f(n) is O(n4) and is also Ω(n4) . Analysis of Algorithms 60Big-Ω However, Big-O and Big-Omega are distinct. That is, there are cases when a function may have different O( ) and Ω( ).  A simple, and somehow artificial, proof of that can be provided as follows: Assume f(n) = n for n = 0, 1,2, …  Clearly f(n) is O(n), and hence is O(n2) Yet, f(n) is NOT Ω(n2) Also, since f(n) is Ω(n), it is also Ω(1) Yet, f(n) is NOT O(1)Analysis of Algorithms 61Big-Ω In fact, as seen, the hierarchy of Ω() is just the reverse of the one of O() For example, the following code segment: for (int j = 0; j < n; j++)System.out.println (j);is: O(n), O(n log n), O(n2), …And is also:Ω(n), Ω(log n), Ω(1) Analysis of Algorithms 62Big-O, Big-Omega, Big-Theta &Plain English! Big-O provides and upper bound of a function, while Big-Ω provides a lower bound of it.  In many, if not most, cases, there is often a need of one function that would serve as both lower and upper bounds; that is Big-Theta (Big-Θ).  Analysis of Algorithms 63Big-O, Big-Omega, Big-Theta &Plain English!big-Theta Big-Theta is defined as follows: Given functions f(n) and g(n), we say that f(n) is Θ(g(n)) if there are positive constants c1, c2 and n0 such thatc1g(n)  ≤ f(n) ≤ c2g(n)  for n ≥ n0 Simply put, if a function is f(n) is Θ(g(n)), then it is bounded above and below by some constants time g(n); in other words, it is, roughly, bounded above and below by g(n).  Notice that if f(n) is Θ(g(n)), then it is hence both O(g(n)) and Ω(g(n)).Analysis of Algorithms 64Big-Θ Example 2 (Revised Again): What is Θ() of the following function: f(n) = 3n4 + 6n3 + 10n2 + 5n + 4?As seen before, the function is O(n4) and also is Ω(n4) Hence, it is Θ(n4).Analysis of Algorithms 65Big-O, Big-Ω & Big-ΘQuick Examplesf(n) is Θ(g(n)) if it is Ω(n2) and O(n2). We have already seen the former, for the latter recall that f(n) is O(g(n)) if there is a constant c > 0 and an integer constant n0 ≥ 1 such that f(n) < c•g(n) for n ≥ n0 Let c = 5 and n0 = 1• Notice that 5n2 is NOT Θ(n) since it is not O(n) 5n2 is Θ(n2)f(n) is Ω(g(n)) if there is a constant c > 0 and an integer constant n0 ≥ 1 such that f(n) ≥ c•g(n) for n ≥ n0let c = 1 and n0 = 1 5n2 is Ω(n)f(n) is Ω(g(n)) if there is a constant c > 0 and an integer constant n0 ≥ 1 such that f(n) ≥ c•g(n) for n ≥ n0let c = 5 and n0 = 1 5n2 is Ω(n2)Analysis of Algorithms 66Plain English Sometimes, it might be easier to just indicate the behavior of a method through natural language equivalence of Big-Θ. For instance  if f(n) is Θ(n), we indicate that f is “linear in n”.  if f(n) is Θ(n2), we indicate that f is “quadratic in n”.Analysis of Algorithms 67Plain English The following table shows the English-language equivalence of Big-ΘBig-Θ English Θ(c)for some constant c ≥ 0ConstantΘ(log n) Logarithmic in nΘ(n) Linear in nΘ(n log n) Linear-logarithmic in nΘ(n2) Quadratic in nAnalysis of Algorithms 68Big-O We may just prefer to use plain English, such as “linear”, “quadratic”, etc.. However, in practice, there are MANY occasions when all we specify is an upper bound to the method, which is namely:Big-OAnalysis of Algorithms 69Intuition for Asymptotic NotationBig-O f(n) is O(g(n)) if f(n) is asymptotically less than or equal to g(n)Big-Omega f(n) is Ω(g(n)) if f(n) is asymptotically greater than or equal to g(n)Big-Theta f(n) is Θ(g(n)) if f(n) is asymptotically equal to g(n)Analysis of Algorithms 70Big-O and Growth Rate The big-O notation gives an upper bound on the growth rate of a function The statement “f(n) is O(g(n))” means that the growth rate of f(n) is no more than the growth rate of g(n) We can use the big-O notation to rank functions according to their growth ratef(n) is O(g(n)) g(n) is O(f(n))g(n) grows more Yes Nof(n) grows more No YesSame growth Yes YesAnalysis of Algorithms 71Big-O and Growth Rate Again, we are specifically interested in how rapidly a function increases based on its classification. For instance, suppose that we have a method whose worstTime() estimate is linear in n, what will be the effect of doubling the problem size? worstTime(n) ≈ c * n, for some constant c, and sufficiently large value of n If the problem size doubles then worstTime(n) ≈ c * 2n ≈ 2* worstTime(n)  In other words, if n is doubled, then worst time is doubled.Analysis of Algorithms 72Big-O and Growth Rate Now, suppose that we have a method whose worstTime() estimate is quadratic in n, what will be the effect of doubling the problem size? worstTime(n) ≈ c * n2 If the problem size doubles then worstTime(2n) ≈ c * (2n)2 = c * 4 * n2 ≈ 4* worstTime(n)  In other words, if n is doubled, then worst time is quadrupled.Analysis of Algorithms 73Big-O and Growth RateO(n2)O(n log n) O(n)O(log n)O(1)nworstTime(n)Analysis of Algorithms 74Big-O and Growth Rate Again, remember that the Big-O differences eventually dominate constant factors. For instance if n is sufficiently large, 100 n log n will still be smaller than n2 / 100.  So, the relevance of Big-O, Big-Ω or Bog-Θ may actually depend on how large the problem size may get (i.e. 100,000 or more in the above example). Analysis of Algorithms 75Big-O and Growth Rate The following table provides estimate of needed execution time for various functions of n, if n = 1000,000,000, running on a machine executing 1000,1000 statements per second. Function o f n Time Estimate log2 n .0024 Secondsn 17 Minutes n log2 n 7 Hoursn2 300 YearsAnalysis of Algorithms 76 properties of logarithms:logb(xy) = logbx + logbylogb (x/y) = logbx - logbylogbxa = alogbxlogba = logxa/logxbLog22n = log2n + 1Log24n = log2n + 2 properties of exponentials:a(b+c) = aba cabc = (ab)cab /ac = a(b-c)b = a logabbc = a c*logabSummationsLogarithms and ExponentsProof techniquesBasic probabilityMath you need to Review	Analysis of Algorithms	How to Estimate Efficiency? 	Experimental Studies	Limitations of Experiments	How to Estimate Efficiency? 	Estimating Running Time	Estimating Running Time	Estimating Running Time	Estimating Running Time	Estimating Running Time	Estimating Running Time	Pseudocode	Pseudocode Details	Seven Important Functions	Functions Graphed �Using “Normal” Scale	The Random Access Machine (RAM) Model	Primitive Operations	Counting Primitive Operations	Estimating Running Time	Growth Rate of Running Time	�Why Growth Rate Matters	�Comparison of Two Algorithms	Constant Factors	Big-O Notation	Big-O Notation	Big-O Notation	Big-O Notation	Big-O Notation	Big-O Notation	Big-O Notation	Big-O Notation	Big-O Notation	Big-O Notation	Big-O Notation	Big-O Notation	Big-O Notation	Big-O Notation	Finding Big-O Estimates Quickly 	Finding Big-O Estimates Quickly 	Finding Big-O Estimates Quickly 	Finding Big-O Estimates Quickly 	Finding Big-O Estimates Quickly 	Finding Big-O Estimates Quickly 	Finding Big-O Estimates Quickly 	Asymptotic Algorithm Analysis	Asymptotic Algorithm Analysis	Asymptotic Algorithm Analysis	Asymptotic Algorithm Analysis	Asymptotic Algorithm Analysis	Asymptotic Algorithm Analysis	Slide Number 51	Prefix Averages (Quadratic)	Slide Number 53	Slide Number 54	Slide Number 55	Slide Number 56	Slide Number 57	Big-	Big-	Big-	Big-	Big-O, Big-Omega, Big-Theta &Plain English!	Big-O, Big-Omega, Big-Theta &Plain English!	Big-	Slide Number 65	Plain English	Plain English	Big-O	Intuition for Asymptotic Notation	Big-O and Growth Rate	Big-O and Growth Rate	Big-O and Growth Rate	Big-O and Growth Rate	Big-O and Growth Rate	Big-O and Growth Rate	Math you need to ReviewChart1	1	1	1	10	10	10	100	100	100	1000	1000	1000	10000	10000	10000	100000	100000	100000	1000000	1000000	1000000	10000000	10000000	10000000	100000000	100000000	100000000	1000000000	1000000000	1000000000	10000000000	10000000000	10000000000CubicQuadraticLinearnT(n)1111000100101000000100001001000000000100000010001000000000000100000000100001000000000000000100000000001000001E+18100000000000010000001E+21100000000000000100000001E+241E+161000000001E+271E+1810000000001E+301E+2010000000000Sheet1	n	Linear	Quadratic	Cubic	1	1	1	1	10	10	100	1000	100	100	10000	1000000	1000	1000	1000000	1000000000	10000	10000	100000000	1000000000000	100000	100000	10000000000	1000000000000000	1000000	1000000	1000000000000	1000000000000000000	10000000	10000000	100000000000000	1000000000000000000000	100000000	100000000	10000000000000000	1000000000000000000000000	1000000000	1000000000	1000000000000000000	1000000000000000000000000000	10000000000	10000000000	100000000000000000000	1000000000000000000000000000000Chart1	1	1	1	1	10	10	10	10	100	100	100	100	1000	1000	1000	1000	10000	10000	10000	10000	100000	100000	100000	100000	1000000	1000000	1000000	1000000	10000000	10000000	10000000	10000000	100000000	100000000	100000000	100000000	1000000000	1000000000	1000000000	1000000000	10000000000	10000000000	10000000000	10000000000QuadraticQuadraticLinearLinearnT(n)10010000011001001101000000010010100010110000000001000011000010020000000000010000002000001000110000000000001000000001100000100001.01E+1510000000000101000001000001.001E+17100000000000010010000010000001.0001E+191000000000000001000100000100000001.00001E+211E+16100001000001000000001.000001E+231E+1810000010000010000000001.0000001E+251E+20100000010000010000000000Sheet1	n	n	10^2n + 10^5	n2	10^5n^2 + 10^8n	1	1	100100	1	100100000	10	10	101000	100	1010000000	100	100	110000	10000	11000000000	1000	1000	200000	1000000	200000000000	10000	10000	1100000	100000000	11000000000000	100000	100000	10100000	10000000000	1010000000000000	1000000	1000000	100100000	1000000000000	100100000000000000	10000000	10000000	1000100000	100000000000000	10001000000000000000	100000000	100000000	10000100000	10000000000000000	1000009999999999900000	1000000000	1000000000	100000100000	1000000000000000000	100000100000000000000000	10000000000	10000000000	1000000100000	100000000000000000000	10000001000000000000000000Chart1	1	1	1	2	2	2	4	4	4	8	8	8	16	16	16	32	32	32	64	64	64	128	128	128	256	256	256	512	512	512	1024	1024	10243n2n+10nn3121614212184242684842169674321921386438426612876852225615361034512307220581024Sheet1	n	n	2n+10	3n	1	1	12	3	2	2	14	6	4	4	18	12	8	8	26	24	16	16	42	48	32	32	74	96	64	64	138	192	128	128	266	384	256	256	522	768	512	512	1034	1536	1024	1024	2058	3072Chart1	21	21	23	22	25	23	31	25	20	24	18	23	16	22XASheet1	X	21	23	25	31	20	18	16	A	21	22	23	25	24	23	22Chart1	21	21	23	22	25	23	31	25	20	24	18	23	16	22XASheet1	X	21	23	25	31	20	18	16	A	21	22	23	25	24	23	22